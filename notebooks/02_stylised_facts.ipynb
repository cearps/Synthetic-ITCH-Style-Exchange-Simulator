{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stylised Facts\n",
    "\n",
    "Statistical analysis of simulated exchange events: event distributions,\n",
    "inter-arrival times, return distributions, and volatility clustering.\n",
    "\n",
    "## Data generation\n",
    "\n",
    "```bash\n",
    "./build/qrsdp_run --seed 42 --days 5 --seconds 23400\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "import qrsdp_reader as reader\n",
    "import book_replay as replay\n",
    "import ohlc"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Configuration ---\n",
    "RUN_DIR = Path(\"../output/run_42\")\n",
    "DAY_INDEX = 0  # which day to analyse (0 = first)\n",
    "\n",
    "manifest = reader.load_manifest(RUN_DIR)\n",
    "session = manifest[\"sessions\"][DAY_INDEX]\n",
    "day_file = RUN_DIR / session[\"file\"]\n",
    "header = reader.read_header(day_file)\n",
    "events = reader.read_day(day_file)\n",
    "\n",
    "print(f\"Date: {session['date']}\")\n",
    "print(f\"Events: {len(events):,}\")\n",
    "print(f\"Session: {header['session_seconds']}s, p0 = {header['p0_ticks']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "type_names = [reader.EVENT_TYPES.get(t, f\"UNKNOWN_{t}\") for t in range(6)]\n",
    "type_counts = np.bincount(events[\"type\"], minlength=6)\n",
    "\n",
    "fig_types = go.Figure(\n",
    "    data=go.Bar(\n",
    "        x=type_names,\n",
    "        y=type_counts[:6],\n",
    "        marker_color=[\"#2196F3\", \"#FF5722\", \"#90CAF9\", \"#FFAB91\", \"#4CAF50\", \"#F44336\"],\n",
    "    ),\n",
    "    layout=go.Layout(\n",
    "        title=\"Event Type Distribution\",\n",
    "        xaxis=dict(title=\"Event Type\"),\n",
    "        yaxis=dict(title=\"Count\"),\n",
    "        height=400,\n",
    "        template=\"plotly_white\",\n",
    "    ),\n",
    ")\n",
    "fig_types.show()\n",
    "\n",
    "for name, count in zip(type_names, type_counts[:6]):\n",
    "    print(f\"  {name:>14s}: {count:>10,}  ({100 * count / len(events):.1f}%)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-Arrival Time Distribution\n",
    "\n",
    "For a Poisson process, inter-arrival times should follow an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ts = events[\"ts_ns\"].astype(np.float64)\n",
    "iat_ns = np.diff(ts)\n",
    "iat_us = iat_ns / 1e3  # microseconds\n",
    "\n",
    "# Fit exponential\n",
    "mean_iat = np.mean(iat_us)\n",
    "rate = 1.0 / mean_iat\n",
    "\n",
    "# Histogram with exponential overlay\n",
    "hist_vals, bin_edges = np.histogram(iat_us, bins=200, range=(0, np.percentile(iat_us, 99)))\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "bin_width = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "exp_fit = len(iat_us) * bin_width * rate * np.exp(-rate * bin_centers)\n",
    "\n",
    "fig_iat = go.Figure()\n",
    "fig_iat.add_trace(go.Bar(\n",
    "    x=bin_centers, y=hist_vals, name=\"Observed\",\n",
    "    marker_color=\"#2196F3\", opacity=0.7,\n",
    "))\n",
    "fig_iat.add_trace(go.Scatter(\n",
    "    x=bin_centers, y=exp_fit, name=f\"Exponential fit (\u03bb={rate:.4f}/\u03bcs)\",\n",
    "    mode=\"lines\", line=dict(color=\"red\", width=2),\n",
    "))\n",
    "fig_iat.update_layout(\n",
    "    title=\"Inter-Arrival Time Distribution\",\n",
    "    xaxis=dict(title=\"Inter-arrival time (\u03bcs)\"),\n",
    "    yaxis=dict(title=\"Count\"),\n",
    "    height=400,\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_iat.show()\n",
    "\n",
    "print(f\"Mean IAT: {mean_iat:.2f} \u03bcs\")\n",
    "print(f\"Median IAT: {np.median(iat_us):.2f} \u03bcs\")\n",
    "print(f\"Event rate: {rate:.4f} events/\u03bcs = {rate * 1e6:.0f} events/s\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Distributions at Multiple Scales\n",
    "\n",
    "Mid-price returns at 1s, 10s, and 60s horizons. Real markets show fat tails\n",
    "relative to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "book_data = replay.replay_book(\n",
    "    events,\n",
    "    p0_ticks=header[\"p0_ticks\"],\n",
    "    levels_per_side=header[\"levels_per_side\"],\n",
    "    initial_spread_ticks=header[\"initial_spread_ticks\"],\n",
    "    initial_depth=header[\"initial_depth\"],\n",
    ")\n",
    "\n",
    "bars_all = ohlc.multi_resolution_ohlc(book_data[\"ts_ns\"], book_data[\"mid_ticks\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig_ret = go.Figure()\n",
    "colors = {\"1s\": \"#2196F3\", \"10s\": \"#FF9800\", \"1min\": \"#4CAF50\"}\n",
    "\n",
    "for label in [\"1s\", \"10s\", \"1min\"]:\n",
    "    df = bars_all[label]\n",
    "    returns = df[\"close\"].diff().dropna().values\n",
    "    if len(returns) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Normalise for comparison\n",
    "    mu, sigma = returns.mean(), returns.std()\n",
    "    if sigma > 0:\n",
    "        z = (returns - mu) / sigma\n",
    "    else:\n",
    "        z = returns\n",
    "    \n",
    "    fig_ret.add_trace(go.Histogram(\n",
    "        x=z, name=f\"{label} returns\",\n",
    "        marker_color=colors[label], opacity=0.5,\n",
    "        nbinsx=100, histnorm=\"probability density\",\n",
    "    ))\n",
    "    \n",
    "    kurt = stats.kurtosis(z)\n",
    "    print(f\"  {label:>4s}: n={len(returns):>6,}, \u03c3={sigma:.4f}, kurtosis={kurt:.2f}\")\n",
    "\n",
    "# Normal reference\n",
    "x_norm = np.linspace(-5, 5, 200)\n",
    "fig_ret.add_trace(go.Scatter(\n",
    "    x=x_norm, y=stats.norm.pdf(x_norm),\n",
    "    name=\"N(0,1)\", mode=\"lines\",\n",
    "    line=dict(color=\"black\", width=2, dash=\"dash\"),\n",
    "))\n",
    "\n",
    "fig_ret.update_layout(\n",
    "    title=\"Standardised Return Distributions (check for fat tails)\",\n",
    "    xaxis=dict(title=\"Standardised return\"),\n",
    "    yaxis=dict(title=\"Density\"),\n",
    "    barmode=\"overlay\",\n",
    "    height=450,\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_ret.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns Over Time\n",
    "\n",
    "Time series of mid-price returns at 10s resolution, plus cumulative returns.\n",
    "Useful for visually spotting trending regimes and volatility clusters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "ret_10s = bars_all[\"10s\"][\"close\"].diff().dropna()\n",
    "ret_1min = bars_all[\"1min\"][\"close\"].diff().dropna()\n",
    "time_10s = bars_all[\"10s\"][\"time_s\"].iloc[1:].values\n",
    "time_1min = bars_all[\"1min\"][\"time_s\"].iloc[1:].values\n",
    "cum_10s = ret_10s.cumsum()\n",
    "\n",
    "fig_ts = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.06,\n",
    "    subplot_titles=(\"10s Returns\", \"1min Returns\", \"Cumulative Returns (10s)\"),\n",
    ")\n",
    "\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=time_10s, y=ret_10s.values, mode=\"lines\",\n",
    "               line=dict(color=\"#2196F3\", width=0.5), name=\"10s returns\"),\n",
    "    row=1, col=1,\n",
    ")\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=time_1min, y=ret_1min.values, mode=\"lines\",\n",
    "               line=dict(color=\"#FF9800\", width=0.8), name=\"1min returns\"),\n",
    "    row=2, col=1,\n",
    ")\n",
    "fig_ts.add_trace(\n",
    "    go.Scatter(x=time_10s, y=cum_10s.values, mode=\"lines\",\n",
    "               line=dict(color=\"#4CAF50\", width=1.2), name=\"Cumulative\"),\n",
    "    row=3, col=1,\n",
    ")\n",
    "\n",
    "fig_ts.update_layout(\n",
    "    height=750,\n",
    "    template=\"plotly_white\",\n",
    "    showlegend=False,\n",
    "    xaxis3=dict(title=\"Time (s)\", rangeslider=dict(visible=True)),\n",
    ")\n",
    "fig_ts.update_yaxes(title_text=\"\u0394 price\", row=1, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"\u0394 price\", row=2, col=1)\n",
    "fig_ts.update_yaxes(title_text=\"Cum. return\", row=3, col=1)\n",
    "fig_ts.show()\n",
    "\n",
    "print(f\"10s returns \u2014 mean: {ret_10s.mean():.4f}, std: {ret_10s.std():.4f}, \"\n",
    "      f\"min: {ret_10s.min():.1f}, max: {ret_10s.max():.1f}\")\n",
    "print(f\"1min returns \u2014 mean: {ret_1min.mean():.4f}, std: {ret_1min.std():.4f}, \"\n",
    "      f\"min: {ret_1min.min():.1f}, max: {ret_1min.max():.1f}\")\n",
    "print(f\"Session return: {cum_10s.iloc[-1]:.1f} ticks\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Autocorrelation\n",
    "\n",
    "- **Returns** autocorrelation should be near zero (weak-form efficiency).\n",
    "- **Absolute returns** autocorrelation should be positive (volatility clustering)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def autocorrelation(x, max_lag=50):\n",
    "    \"\"\"Compute autocorrelation for lags 1..max_lag.\"\"\"\n",
    "    x = x - x.mean()\n",
    "    var = np.var(x)\n",
    "    if var == 0:\n",
    "        return np.zeros(max_lag)\n",
    "    result = np.correlate(x, x, mode=\"full\")\n",
    "    result = result[len(x) - 1:]  # positive lags only\n",
    "    result = result / (var * len(x))\n",
    "    return result[1:max_lag + 1]\n",
    "\n",
    "\n",
    "returns_10s = bars_all[\"10s\"][\"close\"].diff().dropna().values\n",
    "abs_returns_10s = np.abs(returns_10s)\n",
    "\n",
    "max_lag = 50\n",
    "acf_ret = autocorrelation(returns_10s, max_lag)\n",
    "acf_abs = autocorrelation(abs_returns_10s, max_lag)\n",
    "lags = np.arange(1, max_lag + 1)\n",
    "\n",
    "fig_acf = go.Figure()\n",
    "fig_acf.add_trace(go.Bar(\n",
    "    x=lags, y=acf_ret, name=\"Returns ACF\",\n",
    "    marker_color=\"#2196F3\", opacity=0.7,\n",
    "))\n",
    "fig_acf.add_trace(go.Bar(\n",
    "    x=lags, y=acf_abs, name=\"|Returns| ACF\",\n",
    "    marker_color=\"#FF5722\", opacity=0.7,\n",
    "))\n",
    "\n",
    "# 95% confidence band\n",
    "ci = 1.96 / np.sqrt(len(returns_10s))\n",
    "fig_acf.add_hline(y=ci, line_dash=\"dash\", line_color=\"grey\", annotation_text=\"95% CI\")\n",
    "fig_acf.add_hline(y=-ci, line_dash=\"dash\", line_color=\"grey\")\n",
    "\n",
    "fig_acf.update_layout(\n",
    "    title=\"Autocorrelation: Returns vs |Returns| (10s bars)\",\n",
    "    xaxis=dict(title=\"Lag\"),\n",
    "    yaxis=dict(title=\"ACF\"),\n",
    "    barmode=\"group\",\n",
    "    height=400,\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "fig_acf.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Shift Frequency Over Time\n",
    "\n",
    "Rolling count of events where the best price changed, measured in 1-minute windows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Identify price shifts: events where best_bid or best_ask changed\n",
    "bid_changes = np.diff(book_data[\"best_bid\"]) != 0\n",
    "ask_changes = np.diff(book_data[\"best_ask\"]) != 0\n",
    "shifts = bid_changes | ask_changes\n",
    "\n",
    "# Bin into 1-minute windows\n",
    "ts_s = book_data[\"ts_ns\"][1:] / 1e9  # skip first to match diff length\n",
    "window_ns = 60_000_000_000  # 1 minute\n",
    "t0 = int(book_data[\"ts_ns\"][0])\n",
    "bins = ((book_data[\"ts_ns\"][1:].astype(np.int64) - t0) // window_ns).astype(np.int64)\n",
    "\n",
    "shift_df = pd.DataFrame({\"bin\": bins, \"shift\": shifts.astype(int)})\n",
    "shift_counts = shift_df.groupby(\"bin\")[\"shift\"].sum()\n",
    "shift_times = t0 / 1e9 + shift_counts.index.values * 60\n",
    "\n",
    "fig_shifts = go.Figure(\n",
    "    data=go.Scatter(\n",
    "        x=shift_times, y=shift_counts.values,\n",
    "        mode=\"lines\", name=\"Shifts/min\",\n",
    "        line=dict(color=\"#9C27B0\"),\n",
    "    ),\n",
    "    layout=go.Layout(\n",
    "        title=\"Price Shift Frequency (1-min rolling)\",\n",
    "        xaxis=dict(title=\"Time (s)\", rangeslider=dict(visible=True)),\n",
    "        yaxis=dict(title=\"Shifts per minute\"),\n",
    "        height=350,\n",
    "        template=\"plotly_white\",\n",
    "    ),\n",
    ")\n",
    "fig_shifts.show()\n",
    "\n",
    "total_shifts = shifts.sum()\n",
    "print(f\"Total price shifts: {total_shifts:,} out of {len(events):,} events ({100 * total_shifts / len(events):.2f}%)\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRSDP (notebooks/venv)",
   "language": "python",
   "name": "qrsdp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}